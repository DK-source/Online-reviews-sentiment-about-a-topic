{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3127818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.metrics import BinaryAccuracy\n",
    "import transformers\n",
    "from transformers import BertTokenizer, TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d1c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_train = pd.read_csv('./Datasets/yelp_review_polarity_csv/fixed_train.csv')\n",
    "rest_test = pd.read_csv('./Datasets/yelp_review_polarity_csv/fixed_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66a01ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rest_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6abb5dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)\n",
    "def remove_html(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "def remove_punct(text):\n",
    "    table=str.maketrans('','',string.punctuation)\n",
    "    return text.translate(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ad1a7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_train['review']=rest_train['review'].apply(lambda x : remove_URL(x))\n",
    "rest_train['review']=rest_train['review'].apply(lambda x : remove_html(x))\n",
    "rest_train['review']=rest_train['review'].apply(lambda x : remove_emoji(x))\n",
    "rest_train['review']=rest_train['review'].apply(lambda x : remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cca12c16",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m split \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m\n\u001b[1;32m----> 6\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((\u001b[43mtrain_tokens\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size) \u001b[38;5;241m*\u001b[39m split)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "seq_len = 256\n",
    "batch_size = 16\n",
    "num_samples = len(rest_train)\n",
    "model_name = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c5ecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "train_tokens = tokenizer(rest_train['review'].tolist(), max_length=seq_len, \n",
    "                         truncation=True, padding='max_length', \n",
    "                         add_special_tokens=True, return_tensors='np')\n",
    "split = 0.8\n",
    "size = int((train_tokens['input_ids'].shape[0] // batch_size) * split)\n",
    "\n",
    "y_train = rest_train['target'].values\n",
    "labels = np.zeros((num_samples, y_train.max() + 1))\n",
    "labels[np.arange(num_samples), y_train] = 1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_tokens['input_ids'], train_tokens['attention_mask'], labels))\n",
    "\n",
    "def map_func(input_ids, masks, labels):\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': masks\n",
    "    }, labels\n",
    "\n",
    "dataset = dataset.map(map_func)\n",
    "dataset = dataset.shuffle(10000).batch(batch_size=batch_size, drop_remainder=True)\n",
    "\n",
    "train_ds = dataset.take(size)\n",
    "val_ds = dataset.skip(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f766be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFAutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Two inputs\n",
    "input_ids = tf.keras.layers.Input(shape=(seq_len,), name='input_ids', dtype='int32')\n",
    "mask = tf.keras.layers.Input(shape=(seq_len,), name='attention_mask', dtype='int32')\n",
    "\n",
    "# Transformer\n",
    "embeddings = model(input_ids, attention_mask=mask)[0]\n",
    "embeddings = embeddings[:, 0, :]\n",
    "# Classifier head\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(embeddings)\n",
    "# x = tf.keras.layers.Dropout(0.1)(x)\n",
    "y = tf.keras.layers.Dense(2, activation='softmax', name='outputs')(x)\n",
    "\n",
    "bert_model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)lse\n",
    "\n",
    "optimizer = Adam(lr=1e-5)\n",
    "loss = CategoricalCrossentropy()\n",
    "acc = BinaryAccuracy()\n",
    "\n",
    "bert_model.compile(optimizer=optimizer, loss=loss, metrics=[acc])\n",
    "\n",
    "history = bert_model.fit(train_ds,validation_data=val_ds,epochs=2,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bcbfb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
